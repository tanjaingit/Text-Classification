{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents 2000\n",
      "First Review (['while', 'watching', 'boiler', 'room', ',', 'i', 'was', 'constantly', 'reminded', 'of', 'last', 'year', \"'\", 's', 'masterpiece', 'fight', 'club', '.', 'both', 'films', 'consist', 'of', 'a', 'predominately', 'male', 'cast', '.', 'both', 'films', 'follow', 'young', 'men', 'as', 'they', 'illicitly', 'fight', 'the', 'traditional', 'system', 'for', 'their', 'own', 'desires', '.', 'and', 'both', 'films', 'are', 'seen', 'through', 'the', 'eyes', 'of', 'one', 'narrator', ',', 'who', 'eventually', 'realizes', 'that', 'these', 'men', 'have', 'to', 'be', 'stopped', '.', 'while', 'boiler', 'room', 'writer', '/', 'director', 'ben', 'younger', 'does', 'not', 'get', 'his', 'point', 'across', 'as', 'well', 'as', 'david', 'fincher', 'does', 'for', 'fight', 'club', ',', 'he', 'does', 'contribute', 'another', 'impressive', 'work', 'to', 'a', 'series', 'of', 'films', 'aiming', 'to', 'represent', 'the', 'new', 'generation', '.', 'a', 'generation', 'which', 'has', 'seen', 'the', 'internet', 'prosper', 'and', 'where', 'everyone', 'wants', 'to', 'be', 'a', 'millionaire', '.', 'paying', 'homage', 'to', 'oliver', 'stone', \"'\", 's', '1987', 'classic', 'wall', 'street', ',', 'younger', 'is', 'almost', 'modernizing', 'the', 'tale', 'by', 'using', 'younger', ',', 'hipper', 'actors', 'to', 'play', 'the', 'greedy', 'villains', 'as', 'opposed', 'to', 'the', 'older', ',', 'more', 'experienced', 'types', '.', 'as', 'is', 'true', 'in', 'real', 'life', ',', 'younger', 'minds', 'are', 'becoming', 'richer', 'and', 'richer', 'from', 'their', 'knowledge', 'of', 'more', 'standard', 'technology', '.', 'boiler', 'room', 'dismisses', 'the', 'notion', 'of', 'ingenuity', 'and', 'shows', 'that', 'greed', 'and', 'desire', 'for', 'power', 'come', 'in', 'all', 'ages', '.', 'another', 'similarity', 'with', 'fight', 'club', 'is', 'that', 'both', 'films', 'are', 'not', 'action', 'flicks', '.', 'some', 'people', 'are', 'convinced', 'that', 'an', 'all', '-', 'male', 'cast', 'automatically', 'means', 'there', 'must', 'be', 'gory', 'violence', ',', 'here', 'is', 'proof', 'that', 'this', 'is', 'not', 'true', '.', 'if', 'you', 'want', 'to', 'see', 'an', 'action', 'movie', 'starring', 'ben', 'affleck', ',', 'go', 'see', 'reindeer', 'games', 'this', 'weekend', '.', 'if', 'you', 'want', 'to', 'see', 'a', 'smart', ',', 'insightful', 'film', 'with', 'excellent', 'acting', 'and', 'a', 'clever', 'script', ',', 'see', 'boiler', 'room', '.', 'giovanni', 'ribisi', 'gives', 'an', 'outstanding', 'performance', 'as', 'the', 'film', \"'\", 's', 'narrator', ',', 'seth', '.', 'after', 'dropping', 'out', 'of', 'college', 'and', 'running', 'a', 'lucrative', 'gambling', 'center', 'for', 'college', 'students', 'in', 'his', 'apartment', ',', 'seth', 'is', 'offered', 'a', 'high', 'paying', 'job', 'by', 'a', 'wealthy', 'man', '(', 'nicky', 'katt', ')', '.', 'he', 'agrees', 'to', 'take', 'the', 'job', '(', 'in', 'which', 'you', 'are', 'guaranteed', 'to', 'become', 'a', 'millionaire', 'within', 'three', 'years', ')', 'of', 'selling', 'stock', 'to', 'well', '-', 'off', 'americans', 'from', 'the', 'mid', '-', 'west', 'over', 'the', 'telephone', 'and', 'begins', 'to', 'fit', 'in', 'quite', 'well', 'with', 'his', 'co', '-', 'workers', '.', 'learning', 'tricky', 'techniques', 'to', 'deceive', 'innocent', 'people', 'into', 'buying', 'shares', 'of', 'a', 'good', 'in', 'production', ',', 'seth', 'figures', 'this', 'is', 'too', 'good', 'to', 'be', 'true', '.', 'after', 'stumbling', 'into', 'a', 'room', 'at', 'the', 'wrong', 'time', ',', 'he', 'knows', 'there', 'is', 'something', 'no', 'good', 'about', 'this', 'company', '.', 'at', 'this', 'point', ',', 'seth', 'is', 'left', 'with', 'the', 'ultimate', 'choice', ';', 'continue', 'with', 'the', 'american', 'dream', 'and', 'make', 'millions', 'or', 'tell', 'the', 'authorities', 'that', 'something', 'fishy', 'is', 'going', 'on', '.', 'ribisi', 'is', 'believable', 'as', 'seth', 'especially', 'when', 'he', 'shares', 'scenes', 'with', 'ron', 'rifkin', ',', 'playing', 'seth', \"'\", 's', 'dad', '.', 'the', 'two', 'have', 'perfect', 'chemistry', 'as', 'a', 'troubled', 'father', 'and', 'son', 'trying', 'to', 'impress', 'each', 'other', 'and', 'simultaneously', 'impress', 'themselves', '.', 'the', 'transitions', 'from', 'anger', 'to', 'sympathy', 'that', 'these', 'scenes', 'contain', 'are', 'the', 'standout', 'segments', 'of', 'the', 'entire', 'film', '.', 'the', 'supporting', 'cast', 'of', 'greedy', 'co', '-', 'workers', 'is', 'also', 'flawless', '.', 'ben', 'affleck', 'shines', 'in', 'a', 'short', 'but', 'sweet', 'performance', 'as', 'a', 'recruiter', 'for', 'the', 'company', ',', 'nicky', 'katt', 'is', 'fabulous', 'as', 'the', 'ostensibly', 'friendly', 'boss', 'who', 'eventually', 'becomes', 'extremely', 'jealous', 'of', 'seth', ',', 'and', 'vin', 'diesel', 'gives', 'his', 'best', 'performance', 'of', 'his', 'career', 'as', 'the', 'foil', 'character', 'of', 'nicky', 'katt', '.', 'the', 'energy', 'of', 'the', 'cast', 'as', 'a', 'whole', 'makes', 'boiler', 'room', 'well', 'paced', 'and', 'never', 'boring', '.', 'the', 'only', 'major', 'error', 'in', 'the', 'film', 'is', 'that', 'nothing', 'major', 'happens', '.', 'there', 'is', 'no', 'big', 'plot', 'twist', 'or', 'climatic', 'point', 'to', 'make', 'the', 'film', 'more', 'memorable', '.', 'due', 'to', 'the', 'lack', 'of', 'a', 'major', 'event', ',', 'boiler', 'room', 'never', 'finds', 'a', 'suitable', 'genre', 'to', 'fit', 'into', '.', 'the', 'movie', 'is', 'not', 'intense', 'enough', 'to', 'be', 'a', 'thriller', ',', 'the', 'romantic', 'segments', 'involving', 'seth', 'and', 'abby', '(', 'nia', 'long', ')', 'are', 'not', 'properly', 'finalized', ',', 'and', 'the', 'dialogue', 'isn', \"'\", 't', 'funny', 'enough', 'to', 'make', 'it', 'a', 'comedy', '.', 'in', 'having', 'trouble', 'to', 'characterize', 'the', 'movie', 'as', 'a', 'whole', ',', 'boiler', 'room', 'is', 'slightly', 'confused', 'at', 'times', '.', 'it', 'doesn', \"'\", 't', 'seem', 'to', 'know', 'which', 'category', 'to', 'fit', 'itself', 'into', '.', 'one', 'satisfying', 'concluding', 'scene', 'could', 'have', 'changed', 'the', 'whole', 'film', 'for', 'the', 'better', '.', 'otherwise', ',', 'the', 'movie', 'is', 'fun', 'to', 'watch', 'thanks', 'to', 'its', 'lively', 'cast', 'of', 'young', 'actors', '.'], 'pos')\n",
      "Most Common Words: [(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n",
      "Frequency of the word happy: 215\n"
     ]
    }
   ],
   "source": [
    "# build a list of documents -> categorize it into +ve or -ve\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "            for category in movie_reviews.categories()\n",
    "            for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "#shuffle documents\n",
    "random.shuffle(documents)\n",
    "\n",
    "print('Number of Documents {}'.format(len(documents)))\n",
    "print('First Review {}'.format(documents[0]))\n",
    "\n",
    "#list of all the words \n",
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "    \n",
    "#sort these words from most common to least common\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "print('Most Common Words: {}'.format(all_words.most_common(15)))\n",
    "print('Frequency of the word happy: {}'.format(all_words[\"happy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39768\n"
     ]
    }
   ],
   "source": [
    "print(len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nfeatures = find_features(movie_reviews.words('neg/cv000_29416.txt'))\\nfor key, value in features.items():\\n    if value == True:\\n        print(key)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use 4000 most common words as features\n",
    "word_features = list(all_words.keys())[:4000]\n",
    "\n",
    "#a function that determines which of the 4000 features are contained in a given review (1 review = i document)\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    \n",
    "    # key = word from word_features : value = boolean (true for being present in the given review, false otherwise)\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "        \n",
    "    return features\n",
    "\n",
    "#an example of a negative review\n",
    "'''\n",
    "\n",
    "features = find_features(movie_reviews.words('neg/cv000_29416.txt'))\n",
    "for key, value in features.items():\n",
    "    if value == True:\n",
    "        print(key)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now for all the documents\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting featuresets into test/ train sets\n",
    "from sklearn import model_selection\n",
    "#define a seed for reproducibilty\n",
    "seed = 1\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using sklearn algorithms in NLTK\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
    "#training the model\n",
    "model.train(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 0.816\n"
     ]
    }
   ],
   "source": [
    "#test on training dataset\n",
    "accuracy = nltk.classify.accuracy(model, testing)\n",
    "print('SVC Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
